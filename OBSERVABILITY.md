# Solution d'Observabilit√© Compl√®te - TP2 DevOps

## üéØ Architecture d'Observabilit√©

Cette solution impl√©mente les **trois piliers de l'observabilit√©** avec un stack production-ready :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        APPLICATION                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ  ‚îÇ   Frontend   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   Backend    ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ   (React)    ‚îÇ     HTTP     ‚îÇ   (Express)  ‚îÇ                     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îÇ                                       ‚îÇ                             ‚îÇ
‚îÇ                              OpenTelemetry SDK                      ‚îÇ
‚îÇ                                       ‚îÇ                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                        ‚îÇ
                                        ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   OpenTelemetry Collector        ‚îÇ
                    ‚îÇ  - Receive: OTLP (gRPC/HTTP)     ‚îÇ
                    ‚îÇ  - Process: Batch, Filter        ‚îÇ
                    ‚îÇ  - Export: Multiple backends     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ        ‚îÇ        ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚ñº                           ‚ñº                           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  TEMPO  ‚îÇ               ‚îÇ   LOKI   ‚îÇ              ‚îÇPROMETHEUS‚îÇ
    ‚îÇ Tracing ‚îÇ               ‚îÇ   Logs   ‚îÇ              ‚îÇ Metrics  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                          ‚îÇ                        ‚îÇ
         ‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ          ‚îÇ               ‚îÇ                ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
                    ‚ñº                                ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   GRAFANA   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   PROMTAIL     ‚îÇ
              ‚îÇ Visualization‚îÇ              ‚îÇ Log Collection ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Composants de la Stack

### 1. **OpenTelemetry Collector**
**R√¥le** : Point d'entr√©e central pour toutes les donn√©es d'observabilit√©

**Configuration** :
- **Receivers** : OTLP (gRPC + HTTP sur ports 4317/4318)
- **Processors** : Batch, Memory Limiter, Resource Attribution
- **Exporters** :
  - Traces ‚Üí Tempo
  - Metrics ‚Üí Prometheus (Remote Write)
  - Logs ‚Üí Loki

**Fichier** : `k8s/otel-collector.yaml`

**Pourquoi** : 
- D√©couplage entre applications et backends
- Permet de changer de backends sans modifier le code
- Buffering et retry automatique
- Traitement centralis√© (sampling, filtering)

---

### 2. **Prometheus + Prometheus Operator**
**R√¥le** : Collecte et stockage des m√©triques

**Caract√©ristiques** :
- **Prometheus Operator** : Gestion d√©clarative via CRDs (Custom Resource Definitions)
- **ServiceMonitor** : D√©couverte automatique des endpoints m√©triques
- **Remote Write** : Accepte les m√©triques de l'OpenTelemetry Collector
- **Retention** : 7 jours de donn√©es
- **Storage** : PVC 5Gi

**M√©triques collect√©es** :
```prometheus
# HTTP Metrics
tp2devops_http_requests_total
tp2devops_http_request_duration_seconds

# Business Metrics
tp2devops_todo_operations_total{operation="create|update|delete|list"}
tp2devops_todos_active
tp2devops_todos_completed

# System Metrics
tp2devops_backend_nodejs_heap_size_used_bytes
tp2devops_backend_process_cpu_user_seconds_total
```

**Fichier** : `k8s/prometheus-operator.yaml`

**Acc√®s** :
```bash
kubectl port-forward -n observability svc/prometheus 9090:9090
```

---

### 3. **Loki + Promtail**
**R√¥le** : Agr√©gation et requ√™te de logs

#### Loki
- **Backend de stockage** : Logs index√©s par labels (pas par contenu)
- **Stockage** : Filesystem (local) avec PVC 5Gi
- **API** : Compatible LogQL (langage de requ√™te)

#### Promtail
- **DaemonSet** : Un pod sur chaque n≈ìud
- **Collecte** : Logs de tous les pods via `/var/log/pods`
- **Labels automatiques** :
  - `namespace`
  - `pod`
  - `container`
  - Labels Kubernetes

**Format de logs (Backend)** :
```json
{
  "level": "INFO",
  "time": "2025-10-19T16:30:00.000Z",
  "msg": "Todo created",
  "todoId": 123,
  "text": "Example todo"
}
```

**Requ√™tes LogQL exemples** :
```logql
# Tous les logs du namespace tp2devops
{namespace="tp2devops"}

# Logs d'erreur du backend
{namespace="tp2devops", app="backend"} |= "ERROR"

# Logs avec un trace ID sp√©cifique
{namespace="tp2devops"} | json | traceId="abc123"

# Agr√©gation : taux d'erreurs
rate({namespace="tp2devops"} |= "ERROR" [5m])
```

**Fichier** : `k8s/loki-stack.yaml`

---

### 4. **Tempo**
**R√¥le** : Stockage et requ√™te des traces distribu√©es

**Caract√©ristiques** :
- **Protocole** : OTLP (OpenTelemetry Protocol)
- **Stockage** : Local filesystem avec PVC 10Gi
- **Retention** : 1 heure (configurable)
- **TraceQL** : Langage de requ√™te pour les traces

**Structure d'une trace** :
```
Trace ID: a1b2c3d4e5f6...
‚îú‚îÄ Span: HTTP POST /api/todos (15ms)
‚îÇ  ‚îú‚îÄ Span: create_todo (12ms)
‚îÇ  ‚îÇ  ‚îú‚îÄ Span: db_insert (8ms)
‚îÇ  ‚îÇ  ‚îî‚îÄ Span: update_metrics (2ms)
‚îÇ  ‚îî‚îÄ Span: log_operation (1ms)
‚îî‚îÄ Attributes:
   ‚îú‚îÄ http.method: POST
   ‚îú‚îÄ http.route: /api/todos
   ‚îú‚îÄ http.status_code: 201
   ‚îî‚îÄ todo.id: 123
```

**Int√©gration avec Loki** :
- Grafana peut afficher les logs associ√©s √† une trace
- Filtrage automatique par `traceId`

**Fichier** : `k8s/tempo.yaml`

**Acc√®s** :
```bash
kubectl port-forward -n observability svc/tempo 3200:3200
```

---

### 5. **Grafana**
**R√¥le** : Visualisation unifi√©e de toutes les donn√©es

**Datasources configur√©es** :
1. **Prometheus** - M√©triques
2. **Loki** - Logs
3. **Tempo** - Traces

**Features activ√©es** :
- **Trace to Logs** : Cliquer sur une trace ‚Üí voir les logs
- **Trace to Metrics** : Cliquer sur une trace ‚Üí voir les m√©triques
- **Logs to Traces** : Cliquer sur un traceId ‚Üí voir la trace
- **Service Graph** : Visualisation des d√©pendances

**Dashboards** :
- Application Overview (m√©triques HTTP, business)
- Logs Explorer
- Trace Explorer

**Fichier** : `k8s/grafana.yaml`

**Acc√®s** :
```bash
# Via NodePort
http://$(minikube ip):30300

# Credentials
Username: admin
Password: admin
```

---

## üöÄ D√©ploiement

### Pr√©requis

```bash
# Installer Minikube
brew install minikube

# D√©marrer Minikube avec ressources suffisantes
minikube start --cpus=4 --memory=8192 --disk-size=20g

# Installer kubectl
brew install kubectl
```

### D√©ploiement Complet

```bash
# 1. D√©ployer le stack d'observabilit√©
./scripts/setup-observability.sh

# 2. Builder et d√©ployer l'application
./scripts/deploy-application.sh

# 3. V√©rifier le d√©ploiement
kubectl get all -n tp2devops
kubectl get all -n observability
```

### Ordre de D√©ploiement

1. ‚úÖ Namespaces (`namespace.yaml`)
2. ‚úÖ Prometheus Operator (bundle externe)
3. ‚úÖ Prometheus (`prometheus-operator.yaml`)
4. ‚úÖ Loki + Promtail (`loki-stack.yaml`)
5. ‚úÖ Tempo (`tempo.yaml`)
6. ‚úÖ OpenTelemetry Collector (`otel-collector.yaml`)
7. ‚úÖ Grafana (`grafana.yaml`)
8. ‚úÖ Application (Backend + Frontend) (`application.yaml`)

---

## üîç Utilisation

### 1. G√©n√©rer du Trafic

```bash
# Obtenir l'URL de l'application
minikube service frontend -n tp2devops --url

# Ou acc√©der via NodePort
open http://$(minikube ip):30080
```

Interagir avec l'application :
- Cr√©er des todos
- Les marquer comme compl√©t√©es
- Les supprimer

### 2. Voir les M√©triques dans Prometheus

```bash
kubectl port-forward -n observability svc/prometheus 9090:9090
open http://localhost:9090
```

Requ√™tes utiles :
```promql
# Taux de requ√™tes HTTP
rate(tp2devops_http_requests_total[5m])

# Latence p95
histogram_quantile(0.95, rate(tp2devops_http_request_duration_seconds_bucket[5m]))

# Nombre de todos actifs
tp2devops_todos_active
```

### 3. Explorer les Logs dans Grafana

```bash
open http://$(minikube ip):30300
```

1. Aller dans **Explore**
2. S√©lectionner datasource **Loki**
3. Requ√™te : `{namespace="tp2devops", app="backend"}`
4. Filtrer par niveau : `|= "INFO"` ou `|= "ERROR"`

### 4. Visualiser les Traces

1. Dans Grafana ‚Üí **Explore**
2. S√©lectionner datasource **Tempo**
3. **Search** ‚Üí Filtrer par :
   - Service Name: `tp2devops-backend`
   - Operation: `create_todo`, `update_todo`, etc.
4. Cliquer sur une trace pour voir le d√©tail
5. Cliquer sur "Logs for this span" pour corr√©ler avec les logs

---

## üìà M√©triques Disponibles

### HTTP Metrics

| M√©trique | Type | Description |
|----------|------|-------------|
| `tp2devops_http_requests_total` | Counter | Nombre total de requ√™tes HTTP par m√©thode, route, status |
| `tp2devops_http_request_duration_seconds` | Histogram | Dur√©e des requ√™tes HTTP (buckets de 5ms √† 5s) |

### Business Metrics

| M√©trique | Type | Description |
|----------|------|-------------|
| `tp2devops_todo_operations_total` | Counter | Op√©rations sur les todos (create, update, delete, list) |
| `tp2devops_todos_active` | Gauge | Nombre de todos actifs (non compl√©t√©s) |
| `tp2devops_todos_completed` | Gauge | Nombre de todos compl√©t√©s |

### System Metrics (auto-collect√©es)

| M√©trique | Type | Description |
|----------|------|-------------|
| `tp2devops_backend_nodejs_heap_size_used_bytes` | Gauge | M√©moire heap utilis√©e |
| `tp2devops_backend_process_cpu_user_seconds_total` | Counter | CPU user time |
| `tp2devops_backend_process_resident_memory_bytes` | Gauge | M√©moire r√©sidente |

---

## üîó Corr√©lation Metrics-Logs-Traces

### Exemple de Workflow

1. **D√©tection d'un probl√®me dans Grafana (Metrics)**
   - Dashboard montre une latence p95 √©lev√©e sur `/api/todos`

2. **Investigation dans les Logs**
   - Requ√™te Loki : `{namespace="tp2devops"} |= "/api/todos" | json | duration > 100`
   - On trouve un `traceId` dans les logs

3. **Analyse d√©taill√©e dans les Traces**
   - Chercher la trace avec le `traceId`
   - Voir la flame graph : identifier le span lent
   - Voir les attributs : `db_insert` prend 95ms

4. **Retour aux Logs pour le contexte**
   - Depuis la trace, cliquer sur "Logs for this span"
   - Voir les logs pr√©cis de cette op√©ration

---

## üéØ Dashboards Grafana

### Dashboard "Application Overview"

**Panels** :
1. HTTP Requests Rate (Graph)
2. HTTP Request Duration p50/p95/p99 (Graph)
3. Active Todos (Stat)
4. Completed Todos (Stat)
5. Todo Operations Rate (Graph)
6. Error Rate (Graph)
7. Recent Logs (Logs panel)

**Fichier** : `k8s/grafana-dashboards/application-dashboard.json`

---

## üõ†Ô∏è Troubleshooting

### Les m√©triques n'apparaissent pas dans Prometheus

```bash
# V√©rifier que le ServiceMonitor existe
kubectl get servicemonitor -n tp2devops

# V√©rifier les targets dans Prometheus
kubectl port-forward -n observability svc/prometheus 9090:9090
# Aller sur http://localhost:9090/targets

# V√©rifier les logs du backend
kubectl logs -n tp2devops -l app=backend | grep metrics
```

### Les logs ne sont pas dans Loki

```bash
# V√©rifier Promtail
kubectl get pods -n observability -l app=promtail
kubectl logs -n observability -l app=promtail

# V√©rifier Loki
kubectl logs -n observability -l app=loki

# Tester manuellement
kubectl port-forward -n observability svc/loki 3100:3100
curl http://localhost:3100/ready
```

### Les traces ne sont pas dans Tempo

```bash
# V√©rifier l'OpenTelemetry Collector
kubectl logs -n observability -l app=otel-collector

# V√©rifier Tempo
kubectl logs -n observability -l app=tempo

# V√©rifier que le backend envoie bien les traces
kubectl logs -n tp2devops -l app=backend | grep -i "telemetry\|trace"
```

---

## üìö R√©f√©rences

- [OpenTelemetry](https://opentelemetry.io/)
- [Prometheus Operator](https://prometheus-operator.dev/)
- [Grafana Loki](https://grafana.com/oss/loki/)
- [Grafana Tempo](https://grafana.com/oss/tempo/)
- [Grafana](https://grafana.com/docs/grafana/latest/)

---

## üéì Concepts Cl√©s

### Pourquoi OpenTelemetry Collector ?

**Sans Collector** :
```
Application ‚Üí Tempo
Application ‚Üí Prometheus
Application ‚Üí Loki
```
‚ùå Couplage fort  
‚ùå Configuration complexe  
‚ùå Pas de retry/buffering  

**Avec Collector** :
```
Application ‚Üí OTel Collector ‚Üí Tempo/Prometheus/Loki
```
‚úÖ Un seul endpoint  
‚úÖ Changement de backend facile  
‚úÖ Buffering automatique  
‚úÖ Traitement centralis√©  

### Pourquoi Prometheus Operator ?

**Sans Operator** :
- Configuration manuelle de Prometheus
- Red√©marrage pour ajouter des targets
- Gestion manuelle des ConfigMaps

**Avec Operator** :
- CRDs : `Prometheus`, `ServiceMonitor`, `PrometheusRule`
- D√©couverte automatique via labels
- Reconfiguration automatique

### Correlation Logs-Traces

**Dans le code backend** :
```javascript
const traceId = trace.getSpan(context.active())?.spanContext().traceId;
logger.info({ msg: "...", traceId: traceId });
```

**Dans Grafana** :
- Loki configure automatiquement le champ `traceId`
- Tempo sait chercher dans Loki avec ce `traceId`
- Clic dans UI ‚Üí corr√©lation automatique

---

**Stack d'observabilit√© compl√®te et production-ready ! üöÄ**

