# ğŸš€ Quick Start - ObservabilitÃ© ComplÃ¨te

## Choisissez Votre MÃ©thode de DÃ©marrage

### Option 1 : Docker Compose (Le Plus Rapide) âš¡

```bash
# 1. DÃ©marrer toute la stack
docker-compose up -d

# 2. Attendre que tout dÃ©marre (~2 minutes)
docker-compose logs -f

# 3. AccÃ©der aux services
```

**URLs** :
- ğŸŒ **Frontend** : http://localhost:5173
- ğŸ”§ **Backend API** : http://localhost:3001
- ğŸ“Š **Grafana** : http://localhost:3000 (admin/admin)
- ğŸ“ˆ **Prometheus** : http://localhost:9090
- ğŸ“ **Loki** : http://localhost:3100
- ğŸ” **Tempo** : http://localhost:3200

**Tester** :
```bash
# Health check backend
curl http://localhost:3001/health

# CrÃ©er un todo
curl -X POST http://localhost:3001/api/todos \
  -H "Content-Type: application/json" \
  -d '{"text": "Test todo"}'

# Voir les mÃ©triques
curl http://localhost:3001/metrics
```

---

### Option 2 : Kubernetes avec Minikube ğŸ³

```bash
# 1. DÃ©marrer Minikube (si pas dÃ©jÃ  fait)
minikube start --cpus=4 --memory=8192 --disk-size=20g

# 2. Installer le stack d'observabilitÃ©
./scripts/setup-observability.sh

# 3. DÃ©ployer l'application
./scripts/deploy-application.sh

# 4. Obtenir les URLs
echo "Frontend: http://$(minikube ip):30080"
echo "Grafana: http://$(minikube ip):30300"
```

**Port-forwarding** pour les autres services :
```bash
# Dans des terminaux sÃ©parÃ©s
kubectl port-forward -n observability svc/prometheus 9090:9090
kubectl port-forward -n observability svc/loki 3100:3100
kubectl port-forward -n observability svc/tempo 3200:3200
kubectl port-forward -n tp2devops svc/backend 3001:3000
```

---

## ğŸ“Š Explorer l'ObservabilitÃ©

### 1. GÃ©nÃ©rer du Trafic

```bash
# Script pour gÃ©nÃ©rer des requÃªtes
for i in {1..50}; do
  curl -X POST http://localhost:3001/api/todos \
    -H "Content-Type: application/json" \
    -d "{\"text\": \"Todo $i\"}"
  sleep 0.2
done
```

### 2. Voir les MÃ©triques dans Prometheus

```bash
open http://localhost:9090
```

**RequÃªtes utiles** :
```promql
# Taux de requÃªtes HTTP
rate(tp2devops_http_requests_total[5m])

# Latence P95
histogram_quantile(0.95, rate(tp2devops_http_request_duration_seconds_bucket[5m]))

# Todos actifs
tp2devops_todos_active
```

### 3. Explorer les Logs dans Grafana

```bash
open http://localhost:3000  # admin/admin
```

1. Aller dans **Explore** (icÃ´ne boussole)
2. SÃ©lectionner datasource **Loki**
3. RequÃªte : `{namespace="tp2devops", app="backend"}`
4. Voir les logs structurÃ©s JSON

**Filtres utiles** :
```logql
{namespace="tp2devops"} |= "ERROR"
{namespace="tp2devops"} | json | level="INFO"
{namespace="tp2devops"} | json | traceId="..."
```

### 4. Analyser les Traces dans Tempo

1. Dans Grafana â†’ **Explore**
2. SÃ©lectionner datasource **Tempo**
3. Cliquer sur **Search**
4. Service Name : `tp2devops-backend`
5. Cliquer sur une trace pour voir le dÃ©tail

**Navigation** :
- ğŸ”¥ **Flame Graph** : Visualisation hiÃ©rarchique des spans
- ğŸ“Š **Span List** : Liste dÃ©taillÃ©e avec durÃ©es
- ğŸ“ **Logs** : Cliquer sur "Logs for this span"

### 5. Dashboard Application

1. Grafana â†’ **Dashboards**
2. Import dashboard :
   - ID : `k8s/grafana-dashboards/application-dashboard.json`
3. Voir :
   - HTTP Request Rate
   - HTTP Request Duration (P50/P95/P99)
   - Active Todos
   - Completed Todos
   - Recent Logs

---

## ğŸ” Workflow de Debugging

### ScÃ©nario : Trouver une RequÃªte Lente

1. **Dashboard** â†’ Voir P95 latency Ã©levÃ©e

2. **Loki** â†’ Chercher les requÃªtes lentes :
   ```logql
   {namespace="tp2devops", app="backend"} 
     | json 
     | duration > 100
   ```

3. **Copier le `traceId`** depuis un log

4. **Tempo** â†’ Rechercher la trace :
   ```
   Explore â†’ Tempo â†’ Search â†’ Trace ID: <paste>
   ```

5. **Flame Graph** â†’ Identifier le span lent

6. **Logs** â†’ Revenir aux logs dÃ©taillÃ©s :
   - Cliquer sur "Logs for this span"

---

## ğŸ› ï¸ Commandes Utiles

### Docker Compose

```bash
# Voir tous les containers
docker-compose ps

# Logs d'un service
docker-compose logs -f backend

# RedÃ©marrer un service
docker-compose restart backend

# ArrÃªter tout
docker-compose down

# Tout nettoyer (y compris volumes)
docker-compose down -v
```

### Kubernetes

```bash
# Voir tous les pods
kubectl get pods -A

# Logs du backend
kubectl logs -n tp2devops -l app=backend --tail=50 -f

# Logs de l'OpenTelemetry Collector
kubectl logs -n observability -l app=otel-collector -f

# Exec dans un pod
kubectl exec -it -n tp2devops deploy/backend -- /bin/sh

# VÃ©rifier les mÃ©triques du backend
kubectl exec -n tp2devops deploy/backend -- curl -s localhost:3000/metrics

# Nettoyer tout
./scripts/cleanup.sh
```

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| `README_OBSERVABILITY.md` | ğŸ“– Vue d'ensemble complÃ¨te |
| `OBSERVABILITY.md` | ğŸ”§ Documentation technique dÃ©taillÃ©e |
| `DEPLOYMENT_GUIDE.md` | ğŸš€ Guide de dÃ©ploiement complet |
| `COMPLETE_OBSERVABILITY_SUMMARY.md` | ğŸ“Š RÃ©sumÃ© exÃ©cutif |
| `QUICK_START.md` | âš¡ Ce fichier |

---

## ğŸ¯ Checklist de Validation

### âœ… VÃ©rifier que tout fonctionne

**Backend** :
- [ ] Health check OK : `curl http://localhost:3001/health`
- [ ] Metrics disponibles : `curl http://localhost:3001/metrics`
- [ ] CRUD fonctionne : crÃ©er/lister/modifier/supprimer todos

**Prometheus** :
- [ ] UI accessible : http://localhost:9090
- [ ] Targets UP : http://localhost:9090/targets
- [ ] MÃ©triques visibles : rechercher `tp2devops_`

**Loki** :
- [ ] API rÃ©pond : `curl http://localhost:3100/ready`
- [ ] Logs visibles dans Grafana Explore

**Tempo** :
- [ ] API rÃ©pond : `curl http://localhost:3200/ready`
- [ ] Traces visibles dans Grafana Explore

**Grafana** :
- [ ] Login fonctionne : admin/admin
- [ ] 3 datasources configurÃ©es
- [ ] Explore fonctionne pour Prometheus/Loki/Tempo
- [ ] Correlation Traces â†’ Logs fonctionne

---

## ğŸ› DÃ©pannage Rapide

### Services ne dÃ©marrent pas

```bash
# Docker Compose
docker-compose logs <service-name>

# Kubernetes
kubectl describe pod <pod-name> -n <namespace>
kubectl logs <pod-name> -n <namespace>
```

### Pas de mÃ©triques

```bash
# VÃ©rifier endpoint
curl http://localhost:3001/metrics

# Kubernetes: vÃ©rifier ServiceMonitor
kubectl get servicemonitor -n tp2devops
kubectl describe servicemonitor backend-metrics -n tp2devops
```

### Pas de logs dans Loki

```bash
# Docker Compose: vÃ©rifier Promtail (n'existe pas en compose, logs directs)
docker-compose logs backend

# Kubernetes: vÃ©rifier Promtail
kubectl logs -n observability daemonset/promtail
```

### Pas de traces dans Tempo

```bash
# VÃ©rifier OpenTelemetry Collector
docker-compose logs otel-collector
# ou
kubectl logs -n observability -l app=otel-collector

# VÃ©rifier backend envoie bien
docker-compose logs backend | grep -i "telemetry\|trace"
```

---

## ğŸ’¡ Conseils

1. **GÃ©nÃ©rez du trafic** pour voir les donnÃ©es
2. **Explorez dans Grafana** - c'est l'interface principale
3. **Utilisez la correlation** - passez de traces â†’ logs â†’ metrics
4. **Consultez la doc** quand vous Ãªtes bloquÃ©

---

## ğŸ‰ C'est Parti !

```bash
# DÃ©marrer la stack
docker-compose up -d

# Attendre 2 minutes
sleep 120

# Ouvrir Grafana
open http://localhost:3000

# Login: admin/admin
# Aller dans Explore et commencer Ã  explorer !
```

**Amusez-vous avec l'observabilitÃ© ! ğŸš€ğŸ“ŠğŸ”**

